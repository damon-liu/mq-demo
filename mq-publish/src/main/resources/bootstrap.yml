server:
  port: 18080

spring:
  application:
    name: stream-publish
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      properties:
        retries: 0 # 重试次数
        acks: 1 # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
        batch-size: 16384 # 批量发送的字节数
        buffer-memory: 33554432 # 缓冲区的大小
#        key.serializer: org.apache.kafka.common.serialization.StringSerializer
#        value.serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: default-group # 默认的消费组ID
      properties:
        # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
        # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
        # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
        auto-offset-reset: earliest
        enable-auto-commit: true  # 是否自动提交offset
        auto-commit-interval: 100 # 提交offset延时(接收到消息后多久提交offset)
        key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
  rabbitmq:
    addresses: localhost
    port: 5672
    username: guest
    password: guest
    virtual-host: /
    publisher-confirm-type: correlated
    publisher-returns: true
  cloud:
    stream:
      binders:
        demo-kafka:
          type: kafka
          environment:
            spring.kafka:
              spring.kafka: ${spring.kafka}
        demo-rabbitmq:
          type: rabbit
          environment:
            spring.rabbitmq: ${spring.rabbitmq}
      demo-kafka-binder: demo-kafka
      demo-rabbit-binder: demo-rabbitmq
      bindings:
        output:
          destination: stream-demo
          binder: ${spring.cloud.stream.demo-kafka-binder}

        face-partition-output:
          destination: face-partition-demo
          binder: ${spring.cloud.stream.demo-kafka-binder}
          producer:
            partitionKeyExpression: payload.age
            partitionCount: 2

        car-group-output:
          destination: car-stream-group-demo
          binder: ${spring.cloud.stream.demo-kafka-binder}
        car-group-ack-input:
          destination: car-stream-group-ack
          binder: ${spring.cloud.stream.demo-kafka-binder}
