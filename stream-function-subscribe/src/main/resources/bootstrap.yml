server:
  port: 18078

spring:
  application:
    name: StreamKafkaFunctionSubscribe1
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      properties:
        retries: 0 # 重试次数
        acks: 1 # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
        batch-size: 16384 # 批量发送的字节数
        buffer-memory: 33554432 # 缓冲区的大小
        key.serializer: org.apache.kafka.common.serialization.StringSerializer
        value.serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: default-group # 默认的消费组ID
      properties:
        # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
        # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
        # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
        enable-auto-commit: false  # 是否自动提交offset
        auto-commit-interval: 100 # 提交offset延时(接收到消息后多久提交offset)
#        key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
#        value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
  rabbitmq:
    addresses: localhost
    port: 5672
    username: guest
    password: guest
    virtual-host: /
    publisher-confirm-type: correlated
    publisher-returns: true

  cloud:
    stream:
      binders:
        demo-kafka:
          type: kafka
          environment:
            spring.kafka: ${spring.kafka}
        demo-rabbitmq:
          type: rabbit
          environment:
            spring.rabbitmq: ${spring.rabbitmq}
      demo-kafka-binder: demo-kafka
      demo-rabbit-binder: demo-rabbitmq
      default-binder: rabbit
      bindings:
        # kafka binding
        inputKafka1-in-0:
          binder: ${spring.cloud.stream.demo-kafka-binder}
          destination: destination-test-kafka
          group: group1
#          consumer:
#            autoCommitOffset: false
        inputKafka2-in-0:
          binder: ${spring.cloud.stream.demo-kafka-binder}
          destination: destination-test-kafka
          group: group2
#          consumer:
#            autoCommitOffset: false

        supplierKafka-in-0:
          binder: ${spring.cloud.stream.demo-kafka-binder}
          destination: destination-supplier-kafka
        functionKafkaConsumer-in-0:
          binder: ${spring.cloud.stream.demo-kafka-binder}
          destination: destination-function-kafka-out

        partitionTopic3-in-0:
          binder: ${spring.cloud.stream.demo-kafka-binder}
          destination: partition-topic-3
          group: group1
          consumer:
            partitioned: true
            instance-index: 0
            instance-count: 3
        partitionTopic3-in-1:
          binder: ${spring.cloud.stream.demo-kafka-binder}
          destination: partition-topic-3
          group: group1
          consumer:
            partitioned: true
            instance-index: 1
            instance-count: 3
        partitionTopic3-in-2:
          binder: ${spring.cloud.stream.demo-kafka-binder}
          destination: partition-topic-3
          group: group1
          consumer:
            partitioned: true
            instance-index: 2
            instance-count: 3


        # rabbit binding
        inputRabbit1-in-0:
          binder: ${spring.cloud.stream.demo-rabbit-binder}
          destination: destination-test-rabbit
          group: group1
        inputRabbit2-in-0:
          binder: ${spring.cloud.stream.demo-rabbit-binder}
          destination: destination-test-rabbit
          group: group2

    function:
      # functionName对应服务中的Bean
      definition: inputKafka1;inputKafka2;inputRabbit1;inputRabbit2;supplierKafka;functionKafkaConsumer;partitionTopic3



